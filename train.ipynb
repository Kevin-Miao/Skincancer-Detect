{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "W&B disabled, running your script from this directory will only write metadata locally.\n"
     ]
    }
   ],
   "source": [
    "!wandb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import wandb\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mapcalc import *\n",
    "from mapcalc import calculate_map, calculate_map_range\n",
    "import dataset\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 2\n",
    "in_dim = (300,300)\n",
    "normalization_data = torch.load('mean-std.pt')\n",
    "num_classes = 7\n",
    "print_every = 10\n",
    "\n",
    "### CONSTANTS\n",
    "diseases = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "mapping = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n",
    "inv_mapping = {mapping[k]:k for k in mapping.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_AP(model, data_loader, metric, idx = 'val_mAP', th=0.5):\n",
    "    \"\"\"\n",
    "    Calculates and stores the average precision in the the metrics dictionary.\n",
    "\n",
    "    model: (nn.Module) model\n",
    "    data_loader: (nn.DataLoader) Dataloader\n",
    "    metric: (Dictionary) Dictionary with Average/Class Meter\n",
    "    \n",
    "    Returns mAP over all classes for IOU threshold of 0.5\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    for dis_in, disease in enumerate(diseases):\n",
    "        for i, data in enumerate(data_loader):\n",
    "            image, target = data\n",
    "            class_id = inv_mapping[target['labels'].item()]\n",
    "            if class_id == disease:\n",
    "                result = model(image)[0]\n",
    "                mAP = calculate_map(target, result, th)\n",
    "                metric[idx].update(dis_in, mAP, n=1)\n",
    "    return  metric[idx].class_average()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes + 1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Metric\n",
    "def train_model(model, optimizer, lr_scheduler, data_loader_train, data_loader_valid, data_loader_test, diseases, config):\n",
    "    best_mAP = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        for i, d in enumerate(data_loader_train):\n",
    "\n",
    "            # Header\n",
    "            header = 10*\"=\"\n",
    "            short_header = 5 * '='\n",
    "            print(header, \"Epoch {}\".format(epoch), header)\n",
    "\n",
    "            # Metric Initialization\n",
    "            metrics = {'val_mAP': ClassMeter(diseases)}\n",
    "            metrics['train_loss'] = AverageMeter()\n",
    "            \n",
    "\n",
    "            # Training\n",
    "            model.train()\n",
    "\n",
    "            image, target = d\n",
    "            image = torch.stack([im.to(device) for im in image])\n",
    "            target = [{k: v.to(device) for k, v in t.items()} for t in target]\n",
    "            losses = model(image, target)\n",
    "            loss = sum(loss for loss in losses.values())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            metrics['train_loss'].update(loss.item(), n=len(target))\n",
    "\n",
    "            # Log to weights and biases\n",
    "            wandb.log({'train_loss': metrics['train_loss'].avg})\n",
    "\n",
    "            # Print every 10 epochs\n",
    "            if i % (print_every) == 0:\n",
    "                print('[Epoch {} | {} {}] Training Loss: {}'.format(epoch, i, len(data_loader_train), metrics['train_loss'].avg))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            calculate_AP(model, data_loader_valid, metrics)\n",
    "            \n",
    "            # Print Summary\n",
    "            print(short_header, \"Validation\", short_header)\n",
    "            current_mAP = metrics['val_mAP'].class_average()\n",
    "            print('[Val average mAP] : {}'.format(current_mAP))                                                                                                                           \n",
    "            # Log Values\n",
    "            wandb.log({'val_mAP': current_mAP, 'epoch':epoch})\n",
    "            for idx, disease in enumerate(diseases):\n",
    "                wandb.log({'val_mAP' + '_' +disease: metrics['val_mAP'].avg[idx], 'epoch': epoch})\n",
    "\n",
    "            # SAVE BEST MODEL\n",
    "            if current_mAP > best_mAP:\n",
    "                torch.save(model.state_dict(), wandb.run.dir +\n",
    "                        '/best.pt'.format(epoch))\n",
    "                best_mAP = current_mAP\n",
    "\n",
    "            # SAVE EVERY FIVE EPOCHS\n",
    "            if epoch % 5 == 0:\n",
    "                torch.save(model.state_dict(), wandb.run.dir +\n",
    "                        '/epoch_{}.pt'.format(epoch))\n",
    "\n",
    "    # fig = draw_box(image, image_id, bbox, target=None, confidence=None)\n",
    "    # wandb.log({'sample_figure': fig, 'epoch':epoch})\n",
    "\n",
    "    # Test mAP\n",
    "    test_metrics = {'test_mAP': ClassMeter(diseases)}\n",
    "    with torch.no_grad():\n",
    "        calculate_AP(model, data_loader_test, test_metrics, idx='test_mAP')\n",
    "    print(header, \"Test\", header)\n",
    "    test_mAP = test_metrics['test_mAP'].class_average()\n",
    "    print('[Test average mAP] : {}'.format(test_mAP))\n",
    "\n",
    "    # LOG STUFF\n",
    "    wandb.log({'test_mAP': test_mAP, 'epoch':epoch})\n",
    "    for idx, disease in enumerate(diseases):\n",
    "        wandb.log({'test_mAP' + '_' + disease: test_metrics['test_mAP'].avg[idx], 'epoch':epoch})\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Offline run mode, not syncing to the cloud.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B is disabled in this directory.  Run `wandb on` to enable cloud syncing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hyperparameter_defaults = dict(\n",
    "num_workers=0,\n",
    "batch_size=2,\n",
    "learning_rate=0.001,\n",
    "epochs=10,)\n",
    "wandb.init(project = 'FSDL - SkinCancerDetection', config=hyperparameter_defaults )\n",
    "config = wandb.config\n",
    "dataset = SkinData('/', 'final.csv', transform=transforms.Compose([ToTensor, Normalizer(normalization_data)]))\n",
    "train_data, test_data, valid_data = torch.utils.data.random_split(dataset,[int(0.7 * len(dataset)), int(0.15 * len(dataset)), int(0.15 * len(dataset))+1],  generator=torch.Generator().manual_seed(42))\n",
    "data_loader_train = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, collate_fn = collate_fn)\n",
    "data_loader_test = torch.utils.data.DataLoader(test_data, batch_size=1)\n",
    "data_loader_valid =  torch.utils.data.DataLoader(valid_data, batch_size=1)\n",
    "model = initialize_model()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, milestones=[15, 30], gamma=0.1, last_epoch=-1)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dictionary = {k:0 for k in np.arange(7)}\n",
    "val_dictionary = {k:0 for k in np.arange(7)}\n",
    "train_dict = {k:0 for k in np.arange(7)}\n",
    "whole_dataset = {k: 0 for k in np.arange(7)}\n",
    "for im, data in test_data:\n",
    "    test_dictionary[data['category_id'].item()] += 1\n",
    "for im, data in valid_data:\n",
    "    val_dictionary[data['category_id'].item()] += 1\n",
    "for im, data in train_data:\n",
    "    train_dict[data['category_id'].item()] += 1\n",
    "for im, data in dataset:\n",
    "    whole_dataset[data['category_id'].item()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n{0: 49, 1: 80, 2: 163, 3: 18, 4: 180, 5: 987, 6: 25}\n{0: 39, 1: 72, 2: 183, 3: 18, 4: 181, 5: 996, 6: 14}\n{0: 239, 1: 362, 2: 753, 3: 79, 4: 752, 5: 4722, 6: 103}\n{0: 327, 1: 514, 2: 1099, 3: 115, 4: 1113, 5: 6705, 6: 142}\n"
     ]
    }
   ],
   "source": [
    "print(mapping)\n",
    "print(test_dictionary)\n",
    "print(val_dictionary)\n",
    "print(train_dict)\n",
    "print(whole_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}